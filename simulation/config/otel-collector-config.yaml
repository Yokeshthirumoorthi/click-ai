# ============================================================
#  OpenTelemetry Collector Configuration
#
#  Flow:
#    Your App
#      → sends OTLP events to port 4317 (gRPC) or 4318 (HTTP)
#      → Collector receives them in the "receivers" section
#      → processes/batches them in the "processors" section
#      → writes to S3 (MinIO) in the "exporters" section
# ============================================================

receivers:
  # ── OTLP receiver ──────────────────────────────────────────
  # This is the standard way any app sends telemetry data.
  # Supports TRACES, METRICS, and LOGS all on the same port.
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317 # your app connects here
      http:
        endpoint: 0.0.0.0:4318 # or here if using HTTP

processors:
  # ── Batch processor ────────────────────────────────────────
  # Instead of writing every single event one by one (slow!),
  # the collector waits and groups them into batches.
  # 5000 events OR 5 seconds — whichever comes first → flush.
  batch:
    send_batch_size: 5000 # flush after 5000 events
    timeout: 5s # or after 5 seconds
    send_batch_max_size: 10000 # never exceed 10000 per batch

  # ── Memory limiter ─────────────────────────────────────────
  # Safety valve: if the collector is using too much RAM,
  # it starts dropping events rather than crashing.
  memory_limiter:
    check_interval: 1s
    limit_mib: 2048 # 2GB max for the collector process
    spike_limit_mib: 512

exporters:
  # ── S3 exporters (write OTLP JSON to MinIO) ──────────────
  # Each signal type gets its own exporter with a separate prefix.
  # The s3-loader reads these files and inserts into ClickHouse.
  awss3/traces:
    s3uploader:
      endpoint: http://minio:9000
      region: us-east-1
      s3_force_path_style: true
      s3_bucket: traces
      s3_prefix: incoming
      file_prefix: otlp_
    marshaler: otlp_json

  awss3/metrics:
    s3uploader:
      endpoint: http://minio:9000
      region: us-east-1
      s3_force_path_style: true
      s3_bucket: traces
      s3_prefix: metrics
      file_prefix: otlp_
    marshaler: otlp_json

  awss3/logs:
    s3uploader:
      endpoint: http://minio:9000
      region: us-east-1
      s3_force_path_style: true
      s3_bucket: traces
      s3_prefix: logs
      file_prefix: otlp_
    marshaler: otlp_json

  # ── Debug logger (optional) ────────────────────────────────
  # Prints events to the collector's stdout so you can verify
  # data is flowing. Remove or set to "none" in production.
  debug:
    verbosity: basic # options: basic | normal | detailed

extensions:
  # Health check endpoint — used by Docker healthcheck
  health_check:
    endpoint: 0.0.0.0:13133

  # zpages: browser-based debug UI at http://localhost:55679
  # Shows live traces, pipeline stats, etc.
  zpages:
    endpoint: 0.0.0.0:55679

# ── Pipeline ───────────────────────────────────────────────────────
# Wire everything together.
# Each pipeline = one type of telemetry data (logs / traces / metrics)
service:
  extensions: [health_check, zpages]

  pipelines:
    # TRACES pipeline: request traces → S3 (OTLP JSON)
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [awss3/traces, debug]

    # METRICS pipeline: counters/gauges → S3 (OTLP JSON)
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [awss3/metrics, debug]

    # LOGS pipeline: app logs → S3 (OTLP JSON)
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [awss3/logs, debug]
